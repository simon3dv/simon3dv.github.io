<!doctype html>
<html>
  <head>
    <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
	 <script src="assets/js/glightbox.js"></script>
  <script src="https://use.fontawesome.com/baff6f55f5.js"></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Siming Fan</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
	 <link href="assets/css/style.css" rel="stylesheet">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="google-site-verification" content="D0ys6wLg07UNB0wxvc8V9r64Pwg4VU6mB_2gZNkVLhc" />
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-Q4DNPR3HF9"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-Q4DNPR3HF9');
    </script>

    <!-- For all browsers -->
    <link rel="stylesheet" href="assets/css/academicons.min.css"/>
    <link rel="stylesheet" href="assets/css/academicons.css"/>

  </head>
  <body>
    <div class="wrapper">	
      <header>
        
		    <img src="English/200K.jpg" width="90%">
			<h1>樊思明</h1>
		<b>个人陈述</b><br>动漫和单机游戏是我最大的爱好。最喜爱的番剧是<a href="https://zh.moegirl.org.cn/zh-hans/%E6%A8%B1%E8%8A%B1%E5%BA%84%E7%9A%84%E5%AE%A0%E7%89%A9%E5%A5%B3%E5%AD%A9"></i>樱花庄的宠物女孩</a>，为此制作了个<a href="https://www.bilibili.com/video/BV1Zs411i77R/?spm_id_from=333.999.0.0"></i>MAD</a>，这部番激励了我成为程序员。我目前(2024.9-now)对AIGC/LLM加速动漫、游戏创作的方向最感兴趣，欢迎加我<a href="https://msng.link/o?https://u.wechat.com/MBTLz4BSV53hVRv4Xvw6ziE=wc" class="author-social" target="_blank"><i class="fa-brands fa-weixin"></i> 微信</a>一起交流学习或者通过<a href="mailto:gzfansiming@gmail.com" class="author-social" target="_blank"><i class="fa-solid fa-envelope"></i> Gmail</a>联系我!(不在看工作机会)<!--如有相关职位推荐请查看我的<a href="https://simon3dv.github.io/research/CV_Chinese.pdf">简历</a>!(2024.09)--><br>
		<b>工作经历</b><br>
		商汤 MIG(移动智能) 05.2023~10.2024 汇报对象是 <br><a href="https://scholar.google.com/citations?user=AerkT0YAAAAJ&hl=en">钱晨</a> 和 <a href="https://scholar.google.com/citations?user=KZn9NWEAAAAJ&hl=zh-CN">刘文韬</a>。<br>
        		商汤 研究院/3DAR部门 08.2020~04.2023 汇报对象是 <a href="https://scholar.google.com.hk/citations?user=beGt3cAAAAAJ&hl=en">林君仪</a> 和 mentor <a href="https://openreview.net/profile?id=~Jingtan_Piao1">朴镜潭</a>。
        	<br>
		<b>教育信息</b><br>
		信息与计算科学学士(计算机科学方向)<br>
        <a href="http://www.math.uestc.edu.cn/">数学科学学院</a><br>
        <a href="https://www.uestc.edu.cn/">电子科技大学(UESTC)</a> 本科08.2017~07.2021</p>
		 <p class="view"><b>Link</b>
    <h3><p class="view"><a href="https://simon3dv.github.io/"><i class="fa-solid fa-house-user"></i> 主页(Chinese)</a></p></h3>
    <!--<h3><p class="view"><a href="https://simon3dv.github.io/English"><i class="fa-solid fa-house"></i> Home(English)</a></p></h3>-->
    <!--<h3><p class="view"><a href="https://simon3dv.github.io/research.html">Research</a></p></h3>-->
    <!--<h3><p class="view"><a href="https://simon3dv.github.io/research/CV_Chinese.pdf">简历(Chinese)</a></p></h3>  -->
    <!--<h3><p class="view"><a href="https://simon3dv.github.io/code.html">Code</a></p></h3> -->
    <!--<h3><p class="view"><a href="https://simon3dv.github.io/teaching.html">Teaching</a></p></h3> -->
    <!--<h3><p class="view"><a href="https://simon3dv.github.io/personal.html">Personal</a></p></h3>-->
	<h3><p class="view"><a href="https://scholar.google.com/citations?user=7PxtlMEAAAAJ&hl=zh-CN&oi=ao">
	<i class="fa-brands fa-google"></i> Google Scholar</a></p></h3> 
        <h3><p class="view"><a href="http://github.com/simon3dv"><i class="fa-brands fa-github"></i> Github</a><br></p></h3> 
    <!--<h4><p class="view"><a href="https://simon3dv.github.io/research/CV_English.pdf"><i class="fa-solid fa-file"></i>  CV</a></p></h4>-->
    <p class="view"><b>Social</b><br>
        <a href="mailto:gzfansiming@gmail.com" class="author-social" target="_blank"><i class="fa-solid fa-envelope"></i> Email</a><br>
        <a href="https://msng.link/o?https://u.wechat.com/MBTLz4BSV53hVRv4Xvw6ziE=wc" class="author-social" target="_blank"><i class="fa-brands fa-weixin"></i> Wechat</a><br>
		<a href="tencent://AddContact/?fromId=45&fromSubId=1&subcmd=all&uin=289965313&website=www.oicqzone.com" class="author-social" target="_blank"><i class="fa-brands fa-qq"></i> QQ</a><br>
        <a href="https://space.bilibili.com/5721608"><i class="fa-brands fa-bilibili"></i> Bilibili</a><br>
        <a href="https://www.cnblogs.com/simingfan/"><i class="fa-solid fa-blog"></i> CNBlog</a><br>
        <a href="https://www.zhihu.com/people/simon3dv/posts"><i class="fa-brands fa-zhihu"></i> Zhihu</a><br>
        <a href="https://www.luogu.com.cn/user/4693#practice"><i class="fa-solid fa-code"></i> Luogu OJ</a><br>
        <!--<a href="http://twitter.com/simon3dv" class="author-social" target="_blank"><i class="fa fa-fw fa-twitter-square"></i> Twitter</a><br>-->
        <!--<a href="http://linkedin.com/in/simon3dv" class="author-social" target="_blank"><i class="fa fa-fw fa-linkedin-square"></i> LinkedIn</a><br>-->

   <!--<p><b>Contact:</b><br>Department of Economics<br>University of Oklahoma<br>322 CCD1, 308 Cate Center Drive<br>Norman, OK 73072</p>-->
   <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </header>
      <section>
      <!--<p>请查看我的<a href="https://simon3dv.github.io/research/CV_Chinese.pdf">简历</a>!</p>-->    



<h1>Open-source Projects in SenseTime Research</h1>
<!--<li>See more visulization in <a href="https://docs.google.com/presentation/d/1cyuVYw5DDlBnUbG2-DLo6fWGgYhiKvTUNeAD8Acf8OI/edit?usp=sharing">[Google Slide].</a>-->
<h2>2024 MultiModal Frame Retrieval in video and Editting</h2>
<!--font style="color:#2DC997";></font>-->
<li><b>VideoLLM检索视频帧</b>
<center>
  <img src="./research/FrameLocalizationWithGPT4o.png" alt="Frame Localization Image" style="width:80%;">
</center>
<center><p>Demo result using our pipeline and GPT4o API</p></center>

<li><b>大规模(18.6M instances)合成姿态文本标注</b>
	<p>该数据集旨在解决姿态描述标注中人工标注过于昂贵(￥0.03/字)和GPT4o标注准确率过低(准确率人工:GPT:ours=95%:70%:95%)的问题, 分为(a)单帧姿态描述/(b)双帧姿态变化量描述两个版本, 用于训练文本定位视频帧模型和图像编辑模型。</p>
<div class="video-container" id="videoSlider">
    <div class="video">
        <video src="research/posescript_edit/bedlam.mp4" controls autoplay muted loop></video>
    </div>
    <div class="video">
        <video src="research/posescript_edit/renbody.mp4" controls autoplay muted loop></video>
    </div>
    <div class="video">
        <video src="research/posescript_edit/synbody_v1_1.mp4" controls autoplay muted loop></video>
    </div>
    <div class="video">
        <video src="research/posescript_edit/pw3d.mp4" controls autoplay muted loop></video>
    </div>
    <div class="video">
        <video src="research/posescript_edit/talkshow.mp4" controls autoplay muted loop></video>
    </div>
    <div class="video">
        <video src="research/posescript_edit/ubody.mp4" controls autoplay muted loop></video>
    </div>
    <div class="video">
        <video src="research/posescript_edit/egobody.mp4" controls autoplay muted loop></video>
    </div>
    <div class="video">
        <video src="research/posescript_edit/posetrack.mp4" controls autoplay muted loop></video>
    </div>
</div>

<div class="slider-buttons">
    <button class="arrow left" onclick="changeVideo(-1)">上一个数据集&#8592;</button>
    <button class="arrow right" onclick="changeVideo(1)">下一个数据集&#8594;</button>
</div>

<div id="videoName" style="text-align: center; font-size: 18px; margin-top: 10px; font-weight: bold;"></div>
<div id="nextVideoName" style="text-align: center; font-size: 16px; margin-top: 5px; color: #555;"></div>

<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f9f9f9; /* 背景色 */
        display: flex;
        flex-direction: column;
        align-items: center;
    }
    .video-container {
        display: flex;
        overflow: hidden; /* 防止滚动 */
        white-space: nowrap;
        margin: 20px;
        border-radius: 15px; /* 圆角边框 */
        box-shadow: 0 0px 0px rgba(0, 0, 0, 0.2); /* 阴影效果 */
        background-color: #f9f9f9; /* 视频容器背景色 */
    }
    .video {
        display: inline-block;
        margin: 0px;
    }
    .video video {
        width: 450px;
        height: 450px; /* 视频高度 */
        border-radius: 10px;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.15);
    }
    .slider-buttons {
        text-align: center;
        margin-top: 10px;
        display: flex;
        justify-content: center;
        gap: 20px;
    }
    .arrow {
        padding: 15px;
        font-size: 24px;
        cursor: pointer;
        border: none;
        border-radius: 50%;
        background-color: #4CAF50; /* 按钮背景色 */
        color: white; /* 按钮字体颜色 */
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
        transition: background-color 0.3s ease, box-shadow 0.3s ease;
    }
    .arrow:hover {
        background-color: #45a049; /* 悬停时颜色变化 */
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.3);
    }
    .arrow:focus {
        outline: none;
    }
    #videoName {
        color: #333; /* 视频名称颜色 */
    }
    #nextVideoName {
        color: #555; /* 下一个视频名称颜色 */
    }
</style>

<script>
    const videos = document.querySelectorAll('.video video');
    let currentIndex = 0; // 当前视频索引
    const videoNameDisplay = document.getElementById('videoName');
    const nextVideoNameDisplay = document.getElementById('nextVideoName');

    function updateVideo(index) {
        videos.forEach((video, i) => {
            video.style.display = (i === index) ? 'block' : 'none'; // 仅显示当前视频
        });

        // 更新当前视频名称
        const fileName = videos[index].src.split('/').pop(); // 获取视频文件名
        videoNameDisplay.textContent = `正在播放: ${fileName}`;

        // 更新下一个视频名称
        const nextIndex = (index + 1) % videos.length; // 获取下一个视频索引
        const nextFileName = videos[nextIndex].src.split('/').pop(); // 获取下一个视频文件名
        nextVideoNameDisplay.textContent = `下一个视频: ${nextFileName}`;
    }

    function changeVideo(direction) {
        currentIndex += direction; // 增加或减少索引
        if (currentIndex < 0) {
            currentIndex = videos.length - 1; // 循环到最后一个视频
        } else if (currentIndex >= videos.length) {
            currentIndex = 0; // 循环到第一个视频
        }
        updateVideo(currentIndex); // 更新视频显示
    }

    // 初始化显示第一个视频
    updateVideo(currentIndex);

</script>

<p><center>(a)单帧姿态+Tracking可视化, <a href="https://github.com/naver/posescript">PoseScript</a>的图像版本,图上的文本为当前bbox人物的姿态描述，双击放大以查看详细标注，包括文本,MPJPE(关键点平均误差)和Y轴朝向(±180度为正面)。</center></p>
<script>
  // 等待页面加载完毕后执行代码
  document.addEventListener('DOMContentLoaded', function() {
    // 选择视频元素
    const video = document.querySelector('.listitemimage');
    
    // 当鼠标悬停在视频上时暂停视频
    video.addEventListener('mouseenter', function() {
      video.pause();
    });

    // 当鼠标移开视频时恢复播放
    video.addEventListener('mouseleave', function() {
      video.play();
    });
  });
</script>


<center>
<video width="90%" autoplay muted loop class="listitemimage" >
  <source src="./research/posefix.mp4" type="video/mp4">
</video>
</center>
<p><center>(b)双帧姿态描述变化量+第二帧姿态描述可视化(未Tracking版), <a href="https://arxiv.org/abs/2309.08480">PoseFix</a>的图像版本, 鼠标悬停以暂停。</center></p>

<li><b>细粒度(动作/姿态)文本描述定位视频帧大模型</b>
<center>
<video width="90%" autoplay muted loop class="listitemimage" >
  <source src="./research/yoga_demo_4x.mp4" type="video/mp4">
</video>
</center>
<p><center>(鼠标悬停以放大)</center></p>
<!--<li><b></b>作为对比: 2D姿态匹配视频帧
<center>
<video width="75%" autoplay muted loop class="listitemimage" >
  <source src="./research/pose_matching_4x.mp4" type="video/mp4">
</video>
</center>-->



<br><br>
<h2>2021-2023 Rendering & Animation</h2>

<li><b>3D Animation with Secondary Motion</b>

<center>
<video width="90%" autoplay muted loop class="listitemimage" >
  <source src="./research/snarf+vto.mp4" type="video/mp4">
</video>
</center>
<p><center>(鼠标悬停以放大)</center></p>


<li><b>DNA-Rendering: A Diverse Neural Actor Repository for High-Fidelity Human-centric Rendering</b>.  Wei Cheng, Ruixiang Chen, Wanqi Yin, <u>Siming Fan</u>, Keyu Chen, Honglin He, Huiwen Luo, Zhongang Cai, Jingbo Wang, Yang Gao, Zhengming Yu, Zhengyu Lin, Daxuan Ren, Lei Yang, Ziwei Liu, Chen Change Loy, Chen Qian, Wayne Wu, Dahua Lin, Bo Dai, Kwan-Yee Lin.  <br><b>ICCV2023</b><a href="https://arxiv.org/abs/2307.10173"> [arxiv]</a> <a href="https://dna-rendering.github.io/"> [project page]</a> <a href="https://github.com/DNA-Rendering/DNA-Rendering"> [code]</a>.</font><img src="https://img.shields.io/github/stars/DNA-Rendering/DNA-Rendering.svg" alt="stars">



<li><b>RenderMe-360: A Large Digital Asset Library and Benchmarks Towards High-fidelity Head Avatars</b>.  Pan, Dongwei and Zhuo, Long and Piao, Jingtan and Luo, Huiwen and Cheng, Wei and Wang, Yuxin and <u>Fan, Siming</u> and Liu, Shengqi and Yang, Lei and Dai, Bo and Liu, Ziwei and Loy, Chen Change and Qian, Chen and Wu, Wayne and Lin, Dahua and Lin, Kwan-Yee.  <br>NeurIPS 2023<a href="https://arxiv.org/abs/2305.13353"> [arxiv]</a><a href="https://renderme-360.github.io/"> [project page]</a> <a href="https://github.com/RenderMe-360/RenderMe-360"> [code]</a>.</font><img src="https://img.shields.io/github/stars/RenderMe-360/RenderMe-360.svg" alt="stars">
<center>
<video width="45%" autoplay muted loop class="listitemimage" >
  <source src="./research/teaser_dna_rendering_batch.mp4" type="video/mp4">
</video>
<video width="45%" autoplay muted loop class="listitemimage" >
  <source src="./research/teaser_renderme_360_batch.mp4" type="video/mp4">
</video>
</center>
<p><center>(鼠标悬停以放大)</center></p>

<li><b>Simulating Fluids in Real-World Still Images</b>.  <u>Siming Fan</u>, Jingtan Piao, Chen Qian, Kwan-Yee Lin, Hongsheng Li.  <br><b>ICCV2023 Oral</b><a href="https://arxiv.org/abs/2204.11335"> [arxiv]</a><a href="https://slr-sfs.github.io/"> [project page]</a> <a href="https://github.com/simon3dv/SLR-SFS"> [github]</a>.</font><img src="https://img.shields.io/github/stars/simon3dv/slr-sfs.svg" alt="stars">
</center>


<center>
<video width="90%" autoplay muted loop class="listitemimage" >
  <source src="./research/teaser-slr-sfs_batch.mp4" type="video/mp4">

</video>
</center>
<p><center>(鼠标悬停以放大)</center></p>

<h2>2020 RGB-Lidar 3D Detection & Unsupervised Domain Adaptation</h2>
<li><b>Pytorch version of frustum-pointnets. <a href="https://github.com/simon3dv/frustum_pointnets_pytorch"> [code]</a><img src="https://img.shields.io/github/stars/simon3dv/frustum_pointnets_pytorch.svg" alt="stars"></b>

      <!--<footer>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>-->
      </section>
	  
    </div>
	
    <script src="javascripts/scale.fix.js"></script>
    <script src="https://kit.fontawesome.com/ccebcf5347.js" crossorigin="anonymous"></script>

  </body>
</html>
